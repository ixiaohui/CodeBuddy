[
  {
    "id": "tang-jie",
    "name": "唐杰",
    "title": "智谱首席科学家、清华大学教授",
    "subtitle": "让机器像人一样思考",
    "summary": "唐杰教授分享了智谱在Agent和Coding领域的技术突破，介绍了从Scaling到泛化的演进，以及GLM模型在多模态、长上下文等方面的最新进展。他提出了系统一与系统二的双系统理论，并对未来AI的发展方向进行了展望。",
    "relatedConcepts": ["scaling-law", "agent", "transformer", "rlvr", "system-one-two"],
    "content": [
      {
        "title": "智谱的起源与精神",
        "text": "我们从2019年开始在思考,我们能不能做到让机器像人一样真正在有可能的一点点的思考。所以2019年我们从清华成果转化,当时在学校的大力支持下,我们成立了智谱这么一家公司,我现在在智谱做首席科学家。\n\n我在清华大概有20年,我2006年毕业,到今年正好20年。其实我一直在做的事情,我总结了一下也就两个事:第一,当年做了AMiner系统;第二,现在在做的大模型。\n\n我一直有一个观点,我自己受影响也比较大,我把它叫做像咖啡一样的精神来做事情。2008年这个观点影响我到现在,也就是做事情可能就是要专注,一直做下去。这一次正好有幸碰到AGI这个事情,正好是需要长期投入、长期做的一件事,它不是短平快,今天我做了,明天就能开花结果,后天就结束了,它非常长期,恰恰值得来投入。\n\n我们实验室2019年的时候在图神经网络、知识图谱方面,其实我们在国际上做的还行,但当时我们坚定地把这两个方向暂停了,暂时不做了,所有的人都转向做大模型,所有的人开始启动了大模型相关的研究。"
      },
      {
        "title": "大模型智能水平的演进",
        "text": "大家也知道全球化,其实这张图是在2025年2月份,在整个大模型发展史上,我们把它叫智能水平,这个智能水平已经大大提高了。\n\n从早期的2020年,其实我们看到一些很简单的像MMU和QA的一些问题,当时已经很不错了,到今天基本可以做到非常满分的程度。慢慢地,从最早期一些简单的问题,到了2021、2022年开始做一些数学题、一些需要推理——也就是加减乘除才能做对的问题,这时候我们可以看到模型通过后训练,慢慢地,现在也把这些问题补齐了,而且能力也大大提高。\n\n再到2023、2024年,大家看到模型的发展从原来的只是一些知识记忆,到简单的数学推理,到更复杂的,甚至可以做一些研究生的问题,甚至开始回答一些我们真实世界的问题。比如说SWE Bench里面,其实已经做了很多真实世界的编程问题。这时候我们可以看到模型的能力,智能水平越来越复杂,就像人成长一样——一开始我们在小学里面多看书,慢慢地做数学题,慢慢到了初高中,我们回答一些研究生的复杂推理问题。再到毕业之后,我们开始完成工作上的一些问题,更难的一些问题。"
      },
      {
        "title": "从Scaling到泛化",
        "text": "另外一方面,我们可以看到这个模型,什么叫从Scaling到泛化?我们人一直都希望机器有泛化能力,我教它一点点,它就能举一反三,其实就和人一样。\n\n最早期的时候我们用Transformer训一个模型,把所有的知识记忆下来。我们训的数据越多,我们训的算力越多,它的长时知识的记忆能力越强,也就是说它把世界上所有的知识都背下来了,并且有一定的泛化能力,可以抽象,可以做简单的推理。\n\n第二层是把这个模型进行对齐和推理,让这个模型有更复杂的推理能力以及理解我们的意图。我们需要持续的Scaling SFT,甚至强化学习。\n\n今年是RLVR(可验证奖励强化学习)爆发年。今年我们通过可验证的强化学习,原来为什么这个事情很难做呢?因为原来我们通过人类反馈,我们只能通过人类反馈数据来做,但人类反馈的数据里面噪音也非常多,而且场景也非常单一。但如果我们有一个可验证的环境,这时候我们可以让机器自己去探索、自己去发现这个反馈数据,自己来成长。"
      },
      {
        "title": "技术路线的选择",
        "text": "从原来更多的是数理化的一些推理,从简单的小学、初中、高中到更复杂的GPQA理化生的复杂问题,到更难的甚至是一些奥赛金牌的问题,到今年大家可以看到HLE非常高难度的智能评测基准,现在在开始进行快速的提升。\n\n后来我们2025年初的时候当时在想一个问题,也许在DeepSeek这种范式下,把这种Chat时代基本上差不多算是解决了,也就是说我们做的再好,也许在Chat的问题上可能做到最后跟DeepSeek差不多。\n\n当时我们面临这么一个选择,我们怎么让这个AI下一步朝向哪个方向发展?我们当时的想法也许新的范式是让每个人能够用AI做一件事情,这可能是下一个范式,原来是Chat,现在是真的做事了,所以新的范式开启了。\n\n后来我们选了左边这条路,我们让它有Thinking能力。但是我们也没有放弃右边,我们大概在7月28号做了一件事情,相对来讲还比较成功的,把Coding、Agentic、Reasoning能力整合在一起了。"
      },
      {
        "title": "系统一与系统二",
        "text": "人类认知是双系统,系统一和系统二。\n\n系统一完成了95%的任务,比如说人类问一个问题,中国的首都是什么?大家的回答是系统一,因为你背下来了。或者你说你今晚晚上吃饭吗?你说吃,也是系统一,这些全部是系统一背下来了。只有更复杂的推理问题,比如说我今天晚上要请一个来自四川的朋友大吃一顿,去哪吃?这时候就变成系统二了,它就得琢磨这个四川的朋友是哪里来的,我们去哪大吃一顿,那就是系统二做的事情。系统二在我们日常中只占5%。\n\n对于大模型来讲同样的道理,在2020年我们画了这么一个图,我们当时是说参考人类的AI系统应该长什么样子,有人类的系统一、有人类的系统二,还有一个自学习。\n\n对于系统一来讲,我们在不断地Scaling。如果我们在不停地Scaling数据,这带来了智能上界的提升。同时我们还在Scaling推理,使得机器思考的时间越长,用更多的计算和更多的搜索来找到更准确的解。第三方面是我们在Scaling自学习环境,让这个机器有更多的机会跟外界交互,拿到更多的反馈。"
      },
      {
        "title": "2026年展望",
        "text": "2026年对我来说更重要的是要专注和做一些比较新的东西。\n\n第一,我们要Scaling可能还会继续做下去,但Scaling已知的是我们不断加数据、不断探索上限。还有Scaling未知,就是我们不知道的新的范式是什么。\n\n第二,技术创新。我们会做全新的模型架构创新,解决超长上下文,还有更高效的知识压缩问题,以及我们会实现知识记忆和持续学习,这两个方面加在一起,可能是未来实现让机器比人能力还强一点点的一个机会。\n\n第三,多模态感统,今年是一个热点和重点。因为有了这个能力,我们才使得AI可以实现进入像机器里面的长任务、长时效任务,在我们人的工作环境里面,比如说手机里面、电脑里面,它可以完成我们的长任务。当完成我们的长任务,AI就实现了一个工种,AI变成跟我们人一样,可以帮助我们实现。只有这样,AI才能实现具身,才能进入物理世界。\n\n我相信今年可能是AI for Science的一个爆发年,因为很多能力大大提升,我们可以做更多的事情。"
      }
    ]
  },
  {
    "id": "yang-zhilin",
    "name": "杨植麟",
    "title": "月之暗面创始人、Kimi",
    "subtitle": "Scaling Law、模型架构与Agent智能",
    "summary": "杨植麟的分享充满了技术与公式。通过Token Efficiency和Long Context两个维度优化,最终能实现更强的Agent智能。他强调了Transformer在长上下文场景下的优势,并介绍了Kimi K2和Kimi Linear等新一代架构。",
    "relatedConcepts": ["token-efficiency", "long-context", "transformer"],
    "content": [
      {
        "title": "核心优化方向",
        "text": "通过Token Efficiency和Long Context两个维度优化,最终能实现更强的Agent智能。\n\n他指出Transformer优于LSTM的关键不在短序列,而在长上下文场景下Loss显著更低——这正是Agent时代的核心需求。"
      },
      {
        "title": "Kimi K2的技术突破",
        "text": "团队采用MUON二阶优化器实现2倍Token效率提升,并通过QK-Clip解决训练不稳定问题,成功在万亿参数的Kimi K2上完成稳定训练。\n\nK2已成为中国首个Agent模型,可完成两三百步工具调用,在HLE等核心评测上超越OpenAI。"
      },
      {
        "title": "Kimi Linear新架构",
        "text": "下一代架构Kimi Linear采用Delta Attention线性注意力机制,首次在长程任务上超越全注意力,同时速度提升6-10倍。\n\n这一架构的推出,标志着模型在处理长上下文任务时效率的质的飞跃。"
      },
      {
        "title": "模型品位的重要性",
        "text": "杨植麟强调,接下来的模型需要更多Taste(品位),因为智能不像电力可等价交换,每个模型产生的Token本质上是不同的。\n\n他引用与Kimi的对话:继续开发AGI是因为放弃它意味着放弃人类文明上限,不能因恐惧而停滞。"
      }
    ]
  },
  {
    "id": "lin-junyang",
    "name": "林俊旸",
    "title": "阿里通义千问",
    "subtitle": "Towards a Generalist Agent",
    "summary": "林俊旸介绍了千问在2025年的全面进展,包括Qwen3系列的总体能力提升、多语言支持、长文本能力、推理能力、Coding能力、多模态理解和生成等方面。他提出了向通用智能体发展的愿景。",
    "relatedConcepts": ["generalist-agent", "reasoning", "vla", "multi-turn-rl"],
    "content": [
      {
        "title": "开源与产品",
        "text": "大家如果想用上我们的模型的话,最容易体验到我们开源模型和闭源模型。我们做开源做的比较久,2023年8月3日开始做开源。很多人问我们为什么做开源这一件事情?\n\n我们做开源做的比较久,2023年8月3日开始做开源,很多人问我们为什么做开源这一件事情?很多事情都有机缘巧合的成分在这里,反正开源一路做下来之后做了很多,至少还是比较工业的事情。\n\n我们的模型是比较多的,为什么相对比较多?以前有很多人不理解我们为什么做小模型,但是今天大家都明白小模型还是挺有价值。\n\n小模型最终起源于我们内部用来做实验的1.8B模型,我们做预训练,资源毕竟有限,你做实验的话不能通通用7B的实验来验,就拿1.8B的来验。当时我的师弟跟我说我们要把这个模型开源出去,我非常不理解。我说这个模型在2023年几乎是一个不可用的状态,为什么要开源出去?他跟我说7B很消耗机器资源,很多硕士生和博士生没有机器资源做实验,如果1.8B开源出去的话,很多同学就有机会毕业了,这是很好的初心。"
      },
      {
        "title": "Qwen3系列",
        "text": "Text今年主要是Qwen3系列,现在已经做到3.5,3做的时间比较长一些。因为上一代2.5用了非常长的时间,一个最大的特点是总体能力提升。\n\n今年比较有意思的是reasoning的能力要提升,广义的reasoning是做问题推理,让问题得到更好的解决。\n\n第二个是我们支持的语言及方言,语言没有那么多,加上方言一共有119种。为什么会做多语言这件事情呢?其实也有些机缘巧合的事情,2023年的时候,当时我们觉得只要把中文和英文做好就可以服务好我们需要的人群,但是有一回我遇到韩国朋友,他们在做Solar模型的时候,为什么不用我们的模型做呢?他说你们的模型根本就不懂任何的韩语,我感到非常的受伤,我就去看了一下,后来发现这个事情很简单,顺手就把它做了。\n\n第三个是今天的长文本、长视频可能都是其中一个例子。但是我觉得这件事情很有意思,如果你真的想形成一个具有自我认知的模型,首先上下文得足够长,之前还有人讨论一个问题,你没有必要把很多垃圾放到长上下文里面,但是有了这个以后才能做到下面的理解。所以我们现在一路做到1M以上,实际上我们内部已经做到好几个M,可能还不够。"
      },
      {
        "title": "Reasoning能力的提升",
        "text": "回到刚才的问题,我们这一代模型可能和2024年相比,很大的一个区别是reasoning的能力要提升,广义的reasoning是做问题推理,让问题得到更好的解决。\n\n当时,我们发现一个很有意思的现象,我们自己有超过90%的客户不再使用Thinking模型,大量使用我们QwQ系列的很重要的原因是他们的用户喜欢看机器和自己进行聊天。\n\n但是还有一个遗憾,这个模型还有很多东西没有做完,这里是一个取舍的问题。比如说Coding和Agent能力怎么把它集成进去,做起来很难。考虑到自己的技术实力和状况,包括自己一直做Coder系列,我们推出了这个模型。"
      },
      {
        "title": "Coding:从竞赛题到Software Engineer",
        "text": "今天的Coder和过往的不太一样。比如说去年和前年都在解单纯的竞赛题,给一道题看一看能不能把答案做出来。今天我们做什么事情呢?Software Engineer,2024年的时候大家非常惊讶,第一个AI能不能像一个程序员,今天我就维护一个项目这件事情挺难的,你把它做了就好了。\n\n实际做的过程中,这个事情人做起来步骤挺复杂,最简单的是至少我可以打开这些文件夹,看了这些文件的名字知道我可以点开哪一个,其实是多轮交互的过程。今天做Agent一个很重要的点,为什么大家提多轮环境交互,说白了打开文件夹看一眼,这个其实也是一个跟环境交互的方式。这件事情很重要,并且非常有意思,让我们非常激动,真的能产生产力。"
      },
      {
        "title": "Visual Understanding:给模型装上眼睛",
        "text": "做语言模型其实还要想一个问题,它能不能有眼睛看到这个世界,举个例子。我们刚才提到想做Coding Agent提升生产力,我总得让它操控电脑,看电脑屏幕,没有眼睛就看不到,所以我们毫不犹豫的去做,这是巨大的差异,Visual Understanding就去做可以了。\n\n但是今天很多的模型比人看东西看的更明白,比如说我又近视又散光,基本上不太好使,看不明白。但是上下左右我总归分的很清楚,但是AI很有意思,很细节的东西它看很清楚。\n\n这里讲一下我们这次主要的提升,简略的说一下:\n\n第一,我们大家都在做一件事情,让它操作手机、操控电脑的能力进一步提升。\n\n第二,是它的语言的智力,VL模型能不能当LLM来用,这样才可以追上原生多模态的模型,至少做到技术上让语言的智力能够达到持平状态。\n\n第三,Coding这件事情很重要,但是Coding的输入也可以是图像或者是视频。比如说今天我想做一个APP,想做一个网页,我可以画出来。不一定我用文字写,因为这个很考验人类的表达能力。很多时候大家表达的不一定很清楚,你可以画一个图。\n\n还有对视频的理解,也许是VL下一代的机会。视频是更广义的表达,图片可以理解为是单帧的视频,理解很长的视频是很有意思的一个事情。"
      }
    ]
  },
  {
    "id": "round-table",
    "name": "圆桌对话",
    "title": "嘉宾：杨强、唐杰、林俊旸、姚顺雨",
    "subtitle": "中国AI的下一步",
    "summary": "圆桌讨论聚焦于中国AI产业的未来发展方向,涵盖了模型分化、下一个范式、Agent战略、中美差距等关键议题。嘉宾们从不同角度探讨了AI技术、应用和产业的未来。",
    "relatedConcepts": ["to-c-vs-to-b", "autonomous-learning"],
    "content": [
      {
        "title": "模型分化",
        "text": "李广密:我先说第一点,我觉得很明显的是当大家想到AI就是两个,ChatGPT,另外一个Claude Code,是做To C和To B的典范。非常有意思的一点是我们今天用ChatGPT和去年相比的话,感受差别不是太大。但是相反,Coding夸张一点来讲,已经在重塑整个计算机行业做事的方式,人已经不再写代码,而是用英语和电脑去交流。\n\n姚顺雨:我觉得很明显的是当大家想到AI就是两个,ChatGPT,另外一个Claude Code,是做To C和To B的典范。非常有意思的一点是我们今天用ChatGPT和去年相比的话,感受差别不是太大。但是相反,Coding夸张一点来讲,已经在重塑整个计算机行业做事的方式,人已经不再写代码,而是用英语和电脑去交流。\n\n我觉得很核心的一点,对于To C来说,大部分人大部分时候不需要用到这么强的智能,可能今天用ChatGPT和去年相比,写抽象代数和伽罗瓦理论的能力变强了,但是大部分人大部分时候感受不到。大部分人尤其是在中国更多像是搜索引擎的加强版,很多时候也不知道该怎么去用,把它的智能给激发出来。\n\n但对于To B来说,很明显的一点是智能越高,代表生产力越高,值钱的也越来越多,这些东西都是相关的。\n\n第二点观察,垂直整合这条路和模型应用分层这条路的区别。我觉得一个比较好的例子,比如ChatGPT Agent,相比于用Claude或者Gemini加上Manus这样的应用层产品,过去大家会认为当你有垂直整合能力肯定会做的更好,但起码今天来看并不一定。"
      },
      {
        "title": "下一个范式",
        "text": "李广密:接下来第二个比较有意思的问题,今天这个时间点特别特殊,一个是预训练过去走了3年,大家都说可能今天走到了七八成的收益,强化学习也都成为共识,做到了四五十的空间,后面的数据、环境空间很大,接下来一个新的范式,唐老师也谈到了自主学习、自我学习,因为今天这个会的主题是接下来的展望Next,我觉得这是一个特别值得去聊的话题。\n\n姚顺雨:现在自主学习是一个非常热门的词,在硅谷大街小巷咖啡馆里面,大家都在谈论,形成了一个共识。根据我的观察,每个人对这个东西的定义和看法都不一样,我讲两点:\n\n第一,这个事情不是方法论,而是数据或者任务。当我们在谈论自主学习的时候,它到底在什么样的场景下基于什么样的奖励函数去做,你在聊天的时候变得越来越个性化是一种自主学习,在写代码的时候越来越熟悉每个公司独特的环境或者文档是一种自主学习,你去探索新的科学,在这个过程中像一个博士一样,从原来不了解有机化学是什么,到成为这个领域的专家,这也是一种自主学习。每一种自主学习的挑战或者说方法论都不太一样。\n\n第二,我不知道这是不是非共识的,这个事情其实已经在发生了。很明显,ChatGPT在利用用户的数据不断弥合人聊天的风格是什么,使得能感觉到它的好,这是不是一种自我学习?\n\n今天Claude已经写了Claude这个项目95%的代码,它在帮助它自己变得更好,这是不是一种自我学习?"
      },
      {
        "title": "Agent战略",
        "text": "李广密:刚才唐杰老师也聊到怎么衡量智能水平的点,第三个是聊聊Agent战略。最近我跟很多研究员聊,对2026年还有一个很大的预期,Agent今天可以在后台推理3-5个小时,做人类1-2天的工作量,大家期待2026年Agent可能是创造经济价值的关键一年。Agent这个问题,可以让大家展开聊一聊,顺雨刚才提的垂直整合,既有模型,又有Agent产品,包括我们看到硅谷的几个公司,从模型到Agent端到端都做了。顺雨花了很多时间做Agent的研究,你对2026年Agent,比如说Long Agent真的能干人类1-2周的工作,对Agent战略,包括从模型公司的出发点,会怎么思考这个问题?\n\n姚顺雨:我觉得还是像刚刚说的To B和To C不太一样,目前看起来,我觉得To B的情况现在已经达到了在不断上升的曲线,目前看起来好像没有变慢的趋势。\n\n很有意思的一点是它基本上不做什么创新,就是觉得模型预训练变大了,后训练不断地把这些真实世界的任务给做好,会越来越聪明,它就会带来越来越大的价值。\n\n从某种程度来说,做To B,所有的目标这件事更一致,模型的智能越高,解决的任务越多,在To B下带来的收益越大。\n\n做To C的问题是说,大家都DAU或者说产品的指标和模型的智能,很多时候是不相关的,甚至是相反的关系,我觉得这是能够聚焦的另一个很重要的原因,它只要真的把模型越做越好,它的收益越来越高,所有的事情都是非常好的。\n\n目前看起来,To B或者说生产力的Agent刚刚开始,现在除了模型之外,有两个Next,环境问题或者Deployment问题。"
      },
      {
        "title": "中美差距",
        "text": "李广密:我再Follow一个问题,比如说中国的模型跟美国的模型差距,有的地方在追上来,有的地方他们的算力在拉大,你内心中Gap变大的恐惧感强吗?\n\n林俊旸:今天干这一行就不能恐惧,必须得有非常强的心态,对于我们的心态来说,能干这一行就非常不错,能做大模型这件事情已经非常幸运了,能做大模型这件事情已经非常幸运。\n\n我觉得还是看你的初心是什么,刚才顺雨提到一个点,你的模型不一定那么强在C端里边是OK的。我可能转换成另外一个角度去思考这个问题,我们的模型为人类社会带来了什么样的价值,只要我相信我这个东西能够为人类社会带来充分的价值,能够帮助人类,就算不是最强的,我也愿意接受。\n\n李广密:多谢俊旸。有请杨强老师,因为您经历过很多AI的周期,也看过很多中国的AI公司变成世界最强,您对这个问题的判断。\n\n杨强:我们可以回顾一下互联网的发展,一开始也是从美国开始,但中国很快就赶上,而且应用像微信,是世界第一的。我想AI是一个技术,它并不是一个终端的产品,但我们中国有很多聪明才智会把这个产品发挥到极致,不管是To B还是To C,但我可能更看好To C,因为百花齐放,中国人集思广益。但To B可能会有一些限制,像付费意愿、企业文化等也在改变。我最近也在观察商业方向跟商学院的一些同学探讨,比方说美国有一个公司叫Palantir,它的一个理念是不管AI现在发展到什么阶段,我总是能在AI里面发现一些好的东西应用在企业上,中间肯定有gap,我们要给它弥合,它有一个办法叫本体,用的是本体的方法。当然它是通过一种工程的方法,叫前端工程师FDE来解决的。不管怎么样,我觉得像这种就非常值得我们学习,我觉得中国的企业像AI Native的公司应该发展出这样一些To B的Solution来,我相信会的。所以我觉得To C肯定是百花齐放的,To B也会很快的跟上来。"
      }
    ]
  },
  {
    "id": "zhang-bo",
    "name": "张钹",
    "title": "中国科学院院士、清华大学教授",
    "subtitle": "AGI-Next 展望",
    "summary": "张钹院士从科学家的角度深入分析了当前大语言模型的工作原理和局限性。他指出分布式语义方法虽然强大,但存在五个缺失,并对从LLM到Agent的实现路径进行了展望。",
    "relatedConcepts": ["transformer", "agent"],
    "content": [
      {
        "title": "我们现在正在干什么",
        "text": "从刚才各位介绍中,大家都在做大语言模型,实际上最初的就是做一个聊天机器人,也就是说希望机器跟人类能够说话。这个做的结果怎么样?做的结果是这样:\n\n在外部提示下,机器能够在开放领域生成多样性的、语义上连贯的、类似人类的语言。\n\n做到这一点,这一点算不算掌握了人类的语言呢?应该说算,但是还不够彻底,也就是说我们发现它里头有很多地方跟人类语言不一样,这个怎么办?什么原因引起的?大家又问,我们今后究竟通过这个能做到什么程度?最后能不能像人类那样理解自己的工作,而且对自己的问题能够进行反思、能够有意识,哲学来讲叫做有没有自反性。\n\n我们现在从这个出发,究竟现在大语言模型用的什么原理?实际上用了分布式语义的原理,也就是把语义翻译成Firth说的这句话,用它周围共现频率最高的词,来作为这个词的语义,他是这么来定义的。\n\n从这出发,我们就有条件把共现的词变成从共现中学习语义,我们现在就是这么做的。实际上是把原来离散空间里共现的词,变成高维空间里头稀疏的空间,把它变成稠密的向量空间的几何结构,这是一个重大的进步,使得我们语言变成可计算的。因为原来稀疏的共现空间是不能计算的,现在变成稠密的向量空间就可以计算。所以把语言处理的问题完全变成数学计算问题。"
      },
      {
        "title": "五个缺失",
        "text": "可以证明,只要你用的数据量足够多,用的上下文足够长,这个空间就会出现语义关系空间。如果我们有了足够的数据,有了足够长的文本,就会使这个越接近它。大家现在拼命在这方面做工作,这个长度越长越好,数据越多越好,现在基本上趋近于语义关系了。\n\n这个问题现在出在哪里?出在模型是近似的,不是人类语言的真正模型,为什么?因为我们使用的定义是用共现的词来定义语义。关于语义的定义,世界上有七八种不同哲学学派的定义,我们对语义并没有科学的定义,所以现在所用的定义都是不完备的,都是很近似的,所以这就会出现五个缺失:\n\n1. 指称的缺失\n2. 真值和因果的缺失\n3. 语用的缺失\n4. 多义和动态语境的缺失\n5. 闭环行为的缺失\n\n这五个缺失必然会影响到你用语言模型去做应用。所以现在我们要做的就是在干这件事。"
      },
      {
        "title": "我们现在需要干什么",
        "text": "实际上现在大家所做的事情就是要从LLM实现在实际环境下执行复杂任务的Agent,大家现在在做这个事。你把语言模型拿去应用,现在有很多问题,想从语言模型再跨进一步,把它变成可执行复杂任务的Agent。\n\n刚才也有很多报告讲得非常清楚,我们通过这里头的体系结构、算法本身,是会帮助我们不断趋近这个语义关系,但是这个语义关系,是我们目前能够得到最好的,不可能再得到我们真正需要的准确的定义。所以这五个缺失必然存在。"
      }
    ]
  }
]
