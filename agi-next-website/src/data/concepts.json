[
  {
    "id": "transformer",
    "name": "Transformer架构",
    "importance": 1,
    "category": "基础技术层",
    "context": "唐杰:从早期我们用Transformer训一个模型,把所有的知识记忆下来。我们训的数据越多,我们训的算力越多,它的长时知识的记忆能力越强。杨植麟:他指出Transformer优于LSTM的关键不在短序列,而在长上下文场景下Loss显著更低。",
    "experts": ["tang-jie", "yang-zhilin"],
    "description": "Transformer是现代AI模型的基石架构,就像建筑的地基一样重要。你可以把它想象成一台超级智能的阅读机器,它能同时处理整篇文章的所有部分,而不是像人类一样逐字阅读。这使得模型能够理解长篇文章中相隔很远的信息之间的联系。",
    "visualType": "flow",
    "visualData": {
      "title": "如何理解Transformer",
      "steps": [
        {
          "label": "输入文本",
          "content": "把一段话拆分成词语或词块"
        },
        {
          "label": "注意力机制",
          "content": "模型同时看所有词语,找出它们之间的关系"
        },
        {
          "label": "并行处理",
          "content": "所有关系同时计算,像多个人同时工作"
        },
        {
          "label": "输出结果",
          "content": "得到对整个文本的深入理解"
        }
      ]
    }
  },
  {
    "id": "scaling-law",
    "name": "Scaling Law（扩展定律）",
    "importance": 2,
    "category": "基础技术层",
    "context": "唐杰:对于系统一来讲,我们在不断地Scaling。如果我们在不停地Scaling数据,这带来了智能上界的提升。同时我们还在Scaling推理,使得机器思考的时间越长,用更多的计算和更多的搜索来找到更准确的解。",
    "experts": ["tang-jie"],
    "description": "Scaling Law揭示了AI模型能力提升的规律:如果你给模型更多的训练数据、更多的计算资源,它的智能水平就会持续提升。就像读书一样,读的书越多,知识就越丰富。这个定律告诉我们,通过不断增加投入,AI的能力会持续增长,不会很快达到上限。",
    "visualType": "chart",
    "visualData": {
      "title": "Scaling Law示例",
      "description": "随着训练数据量增加,模型能力持续提升",
      "data": [
        { "label": "1B数据", "value": 30 },
        { "label": "10B数据", "value": 45 },
        { "label": "100B数据", "value": 65 },
        { "label": "1T数据", "value": 80 },
        { "label": "10T数据", "value": 90 }
      ]
    }
  },
  {
    "id": "long-context",
    "name": "Long Context（长上下文）",
    "importance": 3,
    "category": "基础技术层",
    "context": "林俊旸:第三个是今天的长文本、长视频可能都是其中一个例子。但是我觉得这件事情很有意思,如果你真的想形成一个具有自我认知的模型,首先上下文得足够长。杨植麟:他指出Transformer优于LSTM的关键不在短序列,而在长上下文场景下Loss显著更低。",
    "experts": ["lin-junyang", "yang-zhilin"],
    "description": "Long Context指的是模型能够记住和处理很长的输入内容。就像人类的短期记忆,比如你能记住整个上午讨论的所有细节。对于AI来说,能够处理长上下文意味着它可以阅读整本书、观看长视频,并理解其中的所有信息关联。",
    "visualType": "comparison",
    "visualData": {
      "title": "短上下文 vs 长上下文",
      "short": {
        "label": "短上下文",
        "description": "只能记住最近几句话",
        "example": "\"北京是中国的首都\" ✓  \"它是中国的政治中心\" ✓  \"今天天气很好\" ✗ (忘记了)"
      },
      "long": {
        "label": "长上下文",
        "description": "能记住整本书的内容",
        "example": "\"第一章讲的是历史\" ✓  \"第十章引用了第一章\" ✓  \"结尾总结全书\" ✓ (全部记住)"
      }
    }
  },
  {
    "id": "reasoning",
    "name": "Reasoning（推理能力）",
    "importance": 4,
    "category": "核心能力层",
    "context": "林俊旸:今年比较有意思的是reasoning的能力要提升,广义的reasoning是做问题推理,让问题得到更好的解决。唐杰:系统二在我们日常中只占5%,只有更复杂的推理问题,比如说请四川朋友大吃一顿,去哪吃,这时候就变成系统二了。",
    "experts": ["lin-junyang", "tang-jie"],
    "description": "推理能力是指AI能够像人类一样进行逻辑思考和问题求解。就像解数学题,不是死记硬背答案,而是通过一步步的推理找到答案。AI的推理能力让它在面对没有见过的问题时,也能通过逻辑分析找到解决方案。",
    "visualType": "flow",
    "visualData": {
      "title": "推理过程示例",
      "example": "问题:如果今天是周五,那后天是周几?",
      "steps": [
        {
          "label": "理解问题",
          "content": "今天=周五,需要计算后天的星期"
        },
        {
          "label": "推理步骤1",
          "content": "明天是周六(周五+1)"
        },
        {
          "label": "推理步骤2",
          "content": "后天是周日(周六+1)"
        },
        {
          "label": "得出答案",
          "content": "答案是:周日"
        }
      ]
    }
  },
  {
    "id": "system-one-two",
    "name": "系统一与系统二",
    "importance": 5,
    "category": "核心能力层",
    "context": "唐杰:人类认知是双系统,系统一和系统二。系统一完成了95%的任务,比如说中国的首都是什么,大家回答是系统一,因为你背下来了。只有更复杂的推理问题,比如说请四川朋友大吃一顿,去哪吃,这是系统二做的。",
    "experts": ["tang-jie"],
    "description": "这是心理学家对人类思维方式的分类:系统一快速、直觉,比如看到1+1马上知道等于2;系统二缓慢、推理,比如解复杂的数学题。现代AI也在模仿这两种思维方式,让模型既能在简单问题上快速回答,也能在复杂问题时进行深入思考。",
    "visualType": "comparison",
    "visualData": {
      "title": "人类思维的双系统",
      "systemOne": {
        "label": "系统一(快思考)",
        "description": "直觉反应,自动完成,占比95%",
        "examples": ["1+1=?", "中国的首都?", "今天吃了吗?"],
        "color": "快速"
      },
      "systemTwo": {
        "label": "系统二(慢思考)",
        "description": "逻辑推理,需要思考,占比5%",
        "examples": ["请四川朋友吃大餐,去哪?", "解复杂数学题", "做重要决策"],
        "color": "深度"
      }
    }
  },
  {
    "id": "token-efficiency",
    "name": "Token Efficiency（令牌效率）",
    "importance": 6,
    "category": "核心能力层",
    "context": "杨植麟:通过Token Efficiency和Long Context两个维度优化,最终能实现更强的Agent智能。团队采用MUON二阶优化器实现2倍Token效率提升。",
    "experts": ["yang-zhilin"],
    "description": "Token是AI处理文本的基本单位,就像字符一样。Token Efficiency指的是让模型用更少的Token理解和表达更多信息。就像写作,高手能用更少的字表达更丰富的意思。提高Token效率可以降低AI的计算成本,让它运行更快。",
    "visualType": "comparison",
    "visualData": {
      "title": "Token效率对比",
      "low": {
        "label": "低效率",
        "description": "需要很多Token表达意思",
        "example": "我 想 去 看 电 影 和 吃 饭"
      },
      "high": {
        "label": "高效率",
        "description": "用更少Token表达相同意思",
        "example": "我想去看电影和吃饭"
      }
    }
  },
  {
    "id": "rlvr",
    "name": "RLVR（可验证奖励强化学习）",
    "importance": 7,
    "category": "学习方法层",
    "context": "唐杰:今年是RLVR(可验证奖励强化学习)爆发年。今年我们通过可验证的强化学习,原来为什么这个事情很难做呢?因为原来我们通过人类反馈,但人类反馈的数据里面噪音也非常多,而且场景也非常单一。",
    "experts": ["tang-jie"],
    "description": "RLVR是一种让AI通过实际验证来学习的方法,就像学生做练习题后对答案,知道自己做得对不对。传统强化学习依赖人类打分,但人类的判断可能不准确。RLVR通过可验证的环境(如编程环境、数学题验证),让AI自己知道答案是否正确,从而更准确地学习。",
    "visualType": "flow",
    "visualData": {
      "title": "RLVR学习流程",
      "steps": [
        {
          "label": "AI尝试解决问题",
          "content": "比如写一段代码"
        },
        {
          "label": "验证结果",
          "content": "运行代码,看是否成功"
        },
        {
          "label": "获得奖励",
          "content": "成功获得奖励,失败获得惩罚"
        },
        {
          "label": "改进策略",
          "content": "根据奖励调整方法,下次做得更好"
        }
      ]
    }
  },
  {
    "id": "multi-turn-rl",
    "name": "Multi-turn RL（多轮强化学习）",
    "importance": 8,
    "category": "学习方法层",
    "context": "林俊旸:所以Multi-turn RL with environment feedback towards long-horizon reasoning,因为很多时候做很多事情需要很长的时间,你得一步步去做。但是AI可以加速很多,比如说人类花两个月的时间做的东西,AI可以花两天的时间。",
    "experts": ["lin-junyang"],
    "description": "Multi-turn RL指的是AI通过多轮次的互动不断学习,就像学习骑自行车,不是一次学会,而是通过多次练习逐渐掌握。这种方式让AI能够完成复杂的长期任务,比如写一篇完整的论文或开发一个软件项目。",
    "visualType": "timeline",
    "visualData": {
      "title": "多轮学习过程",
      "rounds": [
        { "round": 1, "action": "尝试做任务", "result": "有些错误" },
        { "round": 2, "action": "根据反馈改进", "result": "错误减少" },
        { "round": 3, "action": "继续优化", "result": "接近成功" },
        { "round": 4, "action": "最终完善", "result": "任务完成" }
      ]
    }
  },
  {
    "id": "agent",
    "name": "Agent（智能体）",
    "importance": 9,
    "category": "应用形态层",
    "context": "唐杰:新的范式是让每个人能够用AI做一件事情,这可能是下一个范式,原来是Chat,现在是真的做事了,所以新的范式开启了。把Coding、Agentic、Reasoning能力整合在一起了。林俊旸:我们看一看能不能做一个Multimodal Foundation Agent,我特别相信这件事情。",
    "experts": ["tang-jie", "lin-junyang"],
    "description": "Agent是一种能够自主完成任务、与环境交互的AI系统。就像雇佣一个能干的助手,你只需要告诉目标,它会自己规划步骤、调用工具、执行任务,最后给你结果。Agent不再只是和你聊天,而是真正为你做事。",
    "visualType": "flow",
    "visualData": {
      "title": "Agent工作流程",
      "steps": [
        {
          "label": "理解目标",
          "content": "用户提出需求:帮我订一张去长春的高铁票"
        },
        {
          "label": "规划任务",
          "content": "分解步骤:查时间→选车次→订票→确认"
        },
        {
          "label": "执行操作",
          "content": "打开APP,输入信息,完成订票"
        },
        {
          "label": "反馈结果",
          "content": "告知用户订票成功,提供车票信息"
        }
      ]
    }
  },
  {
    "id": "generalist-agent",
    "name": "Generalist Agent（通用智能体）",
    "importance": 10,
    "category": "应用形态层",
    "context": "林俊旸:我们看一看能不能做一个Multimodal Foundation Agent,我特别相信这件事情。今天到这个环节,我比较同意你的观点,叫模型即产品。如果你不断提升模型能力的上限,包括Scaling能做上去,确实能够做到这个事情。",
    "experts": ["lin-junyang"],
    "description": "通用智能体是指能够处理各种不同任务的AI系统,就像一个全能的专家,既能写代码,又能写文章,还能做数据分析。相比只能做一件事的专用智能体,通用智能体具有更强的适应性和灵活性。",
    "visualType": "comparison",
    "visualData": {
      "title": "专用 vs 通用智能体",
      "specialist": {
        "label": "专用智能体",
        "description": "只擅长特定任务",
        "capabilities": ["写代码", "✓", "写文章", "✗", "数据分析", "✗", "图像识别", "✗"]
      },
      "generalist": {
        "label": "通用智能体",
        "description": "能处理多种任务",
        "capabilities": ["写代码", "✓", "写文章", "✓", "数据分析", "✓", "图像识别", "✓"]
      }
    }
  },
  {
    "id": "vla",
    "name": "VLA（视觉-语言-动作模型）",
    "importance": 11,
    "category": "应用形态层",
    "context": "林俊旸:是不是能够把话筒拿起来,今天能够斟茶倒水,这是我们今天很想做的事情。做VLA,做Coding的模型,说白了也是把语言转化成Embodied的模型,从这个角度上来看就非常的振奋人心。",
    "experts": ["lin-junyang"],
    "description": "VLA是将视觉、语言和动作结合在一起的AI模型,就像给机器人装上了眼睛、耳朵和手脚。它不仅能理解你说的话,还能看到周围环境,然后做出相应的动作。这种模型是让AI真正进入物理世界、像人类一样工作的重要一步。",
    "visualType": "flow",
    "visualData": {
      "title": "VLA的工作方式",
      "steps": [
        {
          "label": "视觉输入",
          "content": "看到桌子上有杯子"
        },
        {
          "label": "语言理解",
          "content": "听到指令:把杯子递给我"
        },
        {
          "label": "动作执行",
          "content": "伸出手臂,握住杯子,递给人"
        },
        {
          "label": "结果",
          "content": "成功完成递杯子任务"
        }
      ]
    }
  },
  {
    "id": "embodied-reasoning",
    "name": "Embodied Reasoning（具身推理）",
    "importance": 12,
    "category": "应用形态层",
    "context": "林俊旸:如果走向物理世界,是不是能够把话筒拿起来,今天能够斟茶倒水,这是我们今天很想的事情。做VLA,做Coding的模型,说白了也是把语言转化成Embodied的模型。",
    "experts": ["lin-junyang"],
    "description": "具身推理是指AI在有物理身体的环境中,通过实际操作来思考和解决问题。就像人类通过动手实践来学习,比如学开车不是看书学会的,而是通过实际驾驶逐渐掌握。具身推理让AI能够在真实世界中积累经验,变得更智能。",
    "visualType": "comparison",
    "visualData": {
      "title": "虚拟推理 vs 具身推理",
      "virtual": {
        "label": "虚拟推理",
        "description": "在电脑上模拟思考",
        "example": "AI通过学习图片数据理解什么是杯子"
      },
      "embodied": {
        "label": "具身推理",
        "description": "在真实环境中操作学习",
        "example": "机器人实际拿起杯子,感受重量、温度、材质"
      }
    }
  },
  {
    "id": "autonomous-learning",
    "name": "自主学习",
    "importance": 13,
    "category": "未来方向层",
    "context": "姚顺雨:现在自主学习是一个非常热门的词,在硅谷大街小巷咖啡馆里面,大家都在谈论,形成了一个共识。今天的AI系统本质上都有两部分,首先它是一个模型,其次它有个代码库,你怎么去用这个模型。",
    "experts": ["yang-zhilin"],
    "description": "自主学习是指AI系统能够通过自身的体验和交互,不断改进和提升自己的能力,就像人类通过学习和实践不断进步。这被认为是AI的下一个重要范式,有望让AI突破当前能力的瓶颈,实现真正的自我提升。",
    "visualType": "timeline",
    "visualData": {
      "title": "自主学习的发展",
      "stages": [
        { "stage": "初始", "description": "像婴儿,需要大量人工指导" },
        { "stage": "发展中", "description": "能从错误中学习,但仍需监督" },
        { "stage": "成熟", "description": "能够自主发现问题、改进方法" },
        { "stage": "未来", "description": "完全自主学习,不断突破自身局限" }
      ]
    }
  }
]
